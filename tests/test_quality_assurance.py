#!/usr/bin/env python3
"""
æµ‹è¯•è´¨é‡ä¿éšœåŠŸèƒ½
"""

import asyncio
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT))
sys.path.insert(0, str(PROJECT_ROOT.parent))

from hierarchical.actions.quality_assurance import (
    QualityAssuranceSystem,
    ValidationLevel,
    ValidationResult,
    MultiLevelValidator,
    ContinuousImprovementLoop
)

async def test_quality_assurance():
    """æµ‹è¯•è´¨é‡ä¿éšœç³»ç»Ÿ"""
    print("ğŸ§ª æµ‹è¯•è´¨é‡ä¿éšœç³»ç»Ÿ...")
    
    # åˆ›å»ºè´¨é‡ä¿éšœç³»ç»Ÿå®ä¾‹
    qa_system = QualityAssuranceSystem()
    
    # æµ‹è¯•æ•°æ®
    valid_data = {
        "tool_name": "resolve-library-id",
        "tool_args": {
            "libraryName": "react"
        }
    }
    
    invalid_data = {
        "tool_name": "resolve-library-id",
        "tool_args": {
            "libraryName": ""  # ç©ºå€¼ï¼Œä¼šå¯¼è‡´éªŒè¯å¤±è´¥
        }
    }
    
    business_invalid_data = {
        "tool_name": "resolve-library-id",
        "tool_args": {
            "libraryName": "system"  # å—é™çš„åº“åç§°
        }
    }
    
    execution_data = {
        "query": "How to use React hooks effectively?",
        "steps": [
            {
                "step_number": 1,
                "action": {
                    "tool_name": "resolve-library-id",
                    "tool_args": {"libraryName": "react"}
                },
                "observation": "Resolved to /vercel/next.js",
                "status": "success",
                "duration": 2.5
            },
            {
                "step_number": 2,
                "action": {
                    "tool_name": "get-library-docs",
                    "tool_args": {
                        "context7CompatibleLibraryID": "/vercel/next.js",
                        "topic": "hooks"
                    }
                },
                "observation": "Found documentation about React hooks",
                "status": "success",
                "duration": 3.2
            }
        ],
        "final_answer": "React hooks are a powerful feature that allow you to use state and other React features without writing a class.",
        "total_duration": 5.7
    }
    
    user_feedback = {
        "rating": 4,
        "comments": "Good explanation of React hooks, but could include more examples",
        "satisfaction": 0.8,
        "improvement_areas": ["More practical examples", "Better code samples"]
    }
    
    print("\n" + "="*60)
    print("æµ‹è¯•1: å¤šå±‚æ¬¡éªŒè¯å™¨")
    print("="*60)
    
    # æµ‹è¯•å¤šå±‚æ¬¡éªŒè¯å™¨
    validator = MultiLevelValidator()
    
    # è¯­æ³•éªŒè¯
    syntax_report = await validator.validate(valid_data, ValidationLevel.SYNTAX)
    print(f"è¯­æ³•éªŒè¯ç»“æœ: {syntax_report.result.value}")
    print(f"  éªŒè¯ID: {syntax_report.validation_id}")
    print(f"  éªŒè¯å™¨: {syntax_report.validator_name}")
    
    # è¯­ä¹‰éªŒè¯
    semantic_report = await validator.validate(valid_data, ValidationLevel.SEMANTIC)
    print(f"\nè¯­ä¹‰éªŒè¯ç»“æœ: {semantic_report.result.value}")
    print(f"  éªŒè¯ID: {semantic_report.validation_id}")
    print(f"  éªŒè¯å™¨: {semantic_report.validator_name}")
    
    # ä¸šåŠ¡éªŒè¯
    business_report = await validator.validate(valid_data, ValidationLevel.BUSINESS)
    print(f"\nä¸šåŠ¡éªŒè¯ç»“æœ: {business_report.result.value}")
    print(f"  éªŒè¯ID: {business_report.validation_id}")
    print(f"  éªŒè¯å™¨: {business_report.validator_name}")
    
    print("\n" + "="*60)
    print("æµ‹è¯•2: æ— æ•ˆæ•°æ®éªŒè¯")
    print("="*60)
    
    # æµ‹è¯•æ— æ•ˆæ•°æ®éªŒè¯
    invalid_syntax_report = await validator.validate(invalid_data, ValidationLevel.SYNTAX)
    print(f"æ— æ•ˆæ•°æ®è¯­æ³•éªŒè¯ç»“æœ: {invalid_syntax_report.result.value}")
    
    invalid_semantic_report = await validator.validate(invalid_data, ValidationLevel.SEMANTIC)
    print(f"æ— æ•ˆæ•°æ®è¯­ä¹‰éªŒè¯ç»“æœ: {invalid_semantic_report.result.value}")
    
    invalid_business_report = await validator.validate(invalid_data, ValidationLevel.BUSINESS)
    print(f"æ— æ•ˆæ•°æ®ä¸šåŠ¡éªŒè¯ç»“æœ: {invalid_business_report.result.value}")
    
    print("\n" + "="*60)
    print("æµ‹è¯•3: å—é™æ•°æ®éªŒè¯")
    print("="*60)
    
    # æµ‹è¯•å—é™æ•°æ®éªŒè¯
    business_invalid_report = await validator.validate(business_invalid_data, ValidationLevel.BUSINESS)
    print(f"å—é™æ•°æ®ä¸šåŠ¡éªŒè¯ç»“æœ: {business_invalid_report.result.value}")
    if business_invalid_report.details:
        print(f"  è¯¦æƒ…: {business_invalid_report.details}")
    
    print("\n" + "="*60)
    print("æµ‹è¯•4: å¤šå±‚æ¬¡éªŒè¯")
    print("="*60)
    
    # æµ‹è¯•å¤šå±‚æ¬¡éªŒè¯
    multilevel_result = await qa_system.perform_multilevel_validation(valid_data)
    print(f"å¤šå±‚æ¬¡éªŒè¯æ€»ä½“ç»“æœ: {multilevel_result['overall_result'].value}")
    print(f"  æŠ¥å‘Šæ•°é‡: {len(multilevel_result['reports'])}")
    print(f"  å»ºè®®æ•°é‡: {len(multilevel_result['recommendations'])}")
    
    for i, report in enumerate(multilevel_result['reports']):
        print(f"  æŠ¥å‘Š {i+1}:")
        print(f"    çº§åˆ«: {report['level']}")
        print(f"    ç»“æœ: {report['result']}")
    
    print("\n" + "="*60)
    print("æµ‹è¯•5: å¤šå±‚æ¬¡éªŒè¯ï¼ˆæ— æ•ˆæ•°æ®ï¼‰")
    print("="*60)
    
    # æµ‹è¯•å¤šå±‚æ¬¡éªŒè¯ï¼ˆæ— æ•ˆæ•°æ®ï¼‰
    multilevel_invalid_result = await qa_system.perform_multilevel_validation(invalid_data)
    print(f"æ— æ•ˆæ•°æ®å¤šå±‚æ¬¡éªŒè¯æ€»ä½“ç»“æœ: {multilevel_invalid_result['overall_result'].value}")
    print(f"  æŠ¥å‘Šæ•°é‡: {len(multilevel_invalid_result['reports'])}")
    print(f"  å»ºè®®æ•°é‡: {len(multilevel_invalid_result['recommendations'])}")
    
    if multilevel_invalid_result['recommendations']:
        print("  å»ºè®®:")
        for recommendation in multilevel_invalid_result['recommendations'][:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªå»ºè®®
            print(f"    - {recommendation}")
    
    print("\n" + "="*60)
    print("æµ‹è¯•6: æŒç»­æ”¹è¿›å¾ªç¯")
    print("="*60)
    
    # æµ‹è¯•æŒç»­æ”¹è¿›å¾ªç¯
    improvement_result = await qa_system.run_continuous_improvement_cycle(execution_data, user_feedback)
    print("æŒç»­æ”¹è¿›å¾ªç¯ç»“æœ:")
    
    evaluation_metrics = improvement_result.get("evaluation_metrics", [])
    print(f"  è¯„ä¼°æŒ‡æ ‡æ•°é‡: {len(evaluation_metrics)}")
    
    for metric in evaluation_metrics:
        print(f"    æŒ‡æ ‡: {metric['name']}")
        print(f"      å€¼: {metric['value']}")
        print(f"      ç›®æ ‡: {metric['target']}")
        print(f"      æƒé‡: {metric['weight']}")
        print(f"      åˆ†ç±»: {metric['category']}")
    
    user_feedback_data = improvement_result.get("user_feedback", {})
    if user_feedback_data:
        print(f"  ç”¨æˆ·åé¦ˆ:")
        print(f"    è¯„åˆ†: {user_feedback_data.get('user_rating', 'N/A')}")
        print(f"    æ»¡æ„åº¦: {user_feedback_data.get('satisfaction_score', 'N/A')}")
    
    improvement_suggestions = improvement_result.get("improvement_suggestions", [])
    print(f"  æ”¹è¿›å»ºè®®æ•°é‡: {len(improvement_suggestions)}")
    
    for suggestion in improvement_suggestions[:2]:  # åªæ˜¾ç¤ºå‰2ä¸ªå»ºè®®
        print(f"    å»ºè®®: {suggestion['description']}")
        print(f"      åˆ†ç±»: {suggestion['category']}")
        print(f"      ä¼˜å…ˆçº§: {suggestion['priority']}")
        print(f"      é¢„æœŸæ”¶ç›Š: {suggestion['expected_benefit']}")
    
    print("\n" + "="*60)
    print("æµ‹è¯•7: å®Œæ•´è´¨é‡ä¿éšœ")
    print("="*60)
    
    # æµ‹è¯•å®Œæ•´è´¨é‡ä¿éšœ
    quality_result = await qa_system.ensure_quality(valid_data, execution_data, user_feedback)
    print("å®Œæ•´è´¨é‡ä¿éšœç»“æœ:")
    
    validation_result = quality_result.get("validation", {})
    if validation_result:
        print(f"  éªŒè¯ç»“æœ:")
        print(f"    æ€»ä½“ç»“æœ: {validation_result.get('overall_result', 'N/A')}")
        print(f"    æŠ¥å‘Šæ•°é‡: {len(validation_result.get('reports', []))}")
        print(f"    å»ºè®®æ•°é‡: {len(validation_result.get('recommendations', []))}")
    
    improvement_result = quality_result.get("improvement", {})
    if improvement_result:
        print(f"  æ”¹è¿›ç»“æœ:")
        print(f"    è¯„ä¼°æŒ‡æ ‡: {len(improvement_result.get('evaluation_metrics', []))}")
        print(f"    æ”¹è¿›å»ºè®®: {len(improvement_result.get('improvement_suggestions', []))}")
    
    print(f"  è´¨é‡ä¿éšœæ—¶é—´: {quality_result.get('quality_timestamp', 'N/A')}")
    
    print("\n" + "="*60)
    print("æµ‹è¯•8: éªŒè¯ç­‰çº§æµ‹è¯•")
    print("="*60)
    
    # æµ‹è¯•ä¸åŒéªŒè¯ç­‰çº§
    validation_levels = [ValidationLevel.SYNTAX, ValidationLevel.SEMANTIC, ValidationLevel.BUSINESS]
    
    for level in validation_levels:
        print(f"\næµ‹è¯•éªŒè¯ç­‰çº§: {level.value}")
        report = await validator.validate(valid_data, level)
        print(f"  ç»“æœ: {report.result.value}")
        print(f"  éªŒè¯å™¨: {report.validator_name}")
        if report.details:
            print(f"  è¯¦æƒ…å­—æ®µ: {list(report.details.keys())}")
    
    print("\n" + "="*60)
    print("æµ‹è¯•9: æ€§èƒ½è¯„ä¼°")
    print("="*60)
    
    # æµ‹è¯•æ€§èƒ½è¯„ä¼°
    improvement_loop = ContinuousImprovementLoop()
    metrics = await improvement_loop.evaluate_performance(execution_data)
    print(f"æ€§èƒ½è¯„ä¼°æŒ‡æ ‡æ•°é‡: {len(metrics)}")
    
    for metric in metrics:
        print(f"  æŒ‡æ ‡: {metric.name}")
        print(f"    å€¼: {metric.value}")
        print(f"    ç›®æ ‡: {metric.target}")
        print(f"    æƒé‡: {metric.weight}")
        print(f"    åˆ†ç±»: {metric.category}")
    
    print("\n" + "="*60)
    print("æµ‹è¯•10: åé¦ˆæ”¶é›†")
    print("="*60)
    
    # æµ‹è¯•åé¦ˆæ”¶é›†
    feedback_data = await improvement_loop.collect_feedback(user_feedback)
    print("åé¦ˆæ”¶é›†ç»“æœ:")
    print(f"  åé¦ˆID: {feedback_data.get('feedback_id', 'N/A')}")
    print(f"  ç”¨æˆ·è¯„åˆ†: {feedback_data.get('user_rating', 'N/A')}")
    print(f"  ç”¨æˆ·è¯„è®º: {feedback_data.get('user_comments', 'N/A')[:50]}...")
    print(f"  æ»¡æ„åº¦åˆ†æ•°: {feedback_data.get('satisfaction_score', 'N/A')}")
    print(f"  æ”¹è¿›é¢†åŸŸ: {len(feedback_data.get('improvement_areas', []))}")
    
    print("\n" + "="*60)
    print("æµ‹è¯•å®Œæˆ!")
    print("="*60)

if __name__ == "__main__":
    asyncio.run(test_quality_assurance())